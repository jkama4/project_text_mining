{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2db3d7d3",
   "metadata": {},
   "source": [
    "# Named Entity Recognition and Classification (NERC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "386ea98c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import spacy\n",
    "import utils\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "from typing import List, Dict, Set, Tuple, Optional\n",
    "from datasets import load_dataset, Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aba5e389",
   "metadata": {},
   "source": [
    "Add the following in the README"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "47a1ff14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install spacy[transformers]\n",
    "# python -m spacy download en_core_web_sm ADD ! at start\n",
    "# python -m spacy download en_core_web_trf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db631d73",
   "metadata": {},
   "source": [
    "## Data Collection and Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74b3695b",
   "metadata": {},
   "source": [
    "Link to dataset: https://huggingface.co/datasets/eriktks/conll2003"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "328fed7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['id', 'tokens', 'pos_tags', 'chunk_tags', 'ner_tags'],\n",
       "    num_rows: 14041\n",
       "})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ner_train_data_raw: Dataset = load_dataset(\"conll2003\", trust_remote_code=True, split=\"train\") \n",
    "ner_train_data_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "646ea1ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "ner_labels = ner_train_data_raw.features[\"ner_tags\"].feature.names\n",
    "pos_labels = ner_train_data_raw.features[\"pos_tags\"].feature.names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e42388c",
   "metadata": {},
   "source": [
    "Please, adjust the following files accordingly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ff6f815d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_ner_file: str = r\"C:\\Users\\jayde\\OneDrive\\School\\Text Mining for AI\\final_project_tm\\data\\train_data\\NER-train.tsv\"\n",
    "test_data_ner_file: str = r\"C:\\Users\\jayde\\OneDrive\\School\\Text Mining for AI\\final_project_tm\\data\\test_data\\NER-test.tsv\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76ea02ce",
   "metadata": {},
   "source": [
    "By analysing the test set, we discover that it used the spaCy NER."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bdf2a68",
   "metadata": {},
   "source": [
    "Run the following in a new cell to see the results:\n",
    "\n",
    "```python\n",
    "test_bio_ner_tags = utils.gather_test_bio_ner_tags(file_name)\n",
    "test_bio_ner_tags\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c99005d2",
   "metadata": {},
   "source": [
    "Call the following to convert the data to a CSV file:\n",
    "\n",
    "```python\n",
    "utils.nerc_data_to_file(raw_data, file_name)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "14c3f1ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence_id</th>\n",
       "      <th>token_id</th>\n",
       "      <th>token</th>\n",
       "      <th>bio_ner_tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>EU</td>\n",
       "      <td>B-ORG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>rejects</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>German</td>\n",
       "      <td>B-NORP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>call</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>to</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentence_id  token_id    token bio_ner_tag\n",
       "0            0         0       EU       B-ORG\n",
       "1            0         1  rejects           O\n",
       "2            0         2   German      B-NORP\n",
       "3            0         3     call           O\n",
       "4            0         4       to           O"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df: pd.DataFrame = pd.read_csv(train_data_ner_file, sep=\"\\t\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3e2b872",
   "metadata": {},
   "source": [
    "## Training the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d90e69b",
   "metadata": {},
   "source": [
    "Note for ourselves: we could even split the data into train and test still | Or, we use the test data provided by the dataset and just load it seperately"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "230f9e1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Next part ..."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "text_mining_env_fixed",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
